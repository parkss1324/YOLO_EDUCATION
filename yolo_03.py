import torch
import cv2
from deepface import DeepFace

device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
print("ğŸ“¡ Using device:", device)

# YOLOv5 ëª¨ë¸ ë¡œë“œ
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
model.classes = [0]  # í´ë˜ìŠ¤ 0ì€ ì‚¬ëŒ

# ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
img_path = "/Users/parksungsu/Documents/python_opencv/yolov5/data/images/zidane.jpg"
img = cv2.imread(img_path)

# YOLO ì¶”ë¡ 
results = model(img)

# ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
boxes = results.xyxy[0].cpu().numpy()

for box in boxes:
    x1, y1, x2, y2, conf, cls = map(int, box)
    face = img[y1:y2, x1:x2]

    # ì–¼êµ´ì´ ìœ íš¨í•œ ê²½ìš°ë§Œ ë¶„ì„
    if face.size == 0:
        continue

    try:
        # DeepFace ê°ì • ë¶„ì„
        result = DeepFace.analyze(img_path=face, actions=['emotion'], enforce_detection=False)
        emotion = result[0]['dominant_emotion']
        print(f"Detected emotion: {emotion}")

        # ê²°ê³¼ ì¶œë ¥
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img, emotion, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

    except Exception as e:
        print(f"Error analyzing face: {e}")

# ê²°ê³¼ ì´ë¯¸ì§€ ì¶œë ¥
cv2.imshow("Result", img)
cv2.waitKey(0)
cv2.destroyAllWindows()
